# Welcome, xAI

**Curated Repository Hub for Frontier Alignment & Interpretability Collaboration**

Welcome to a joint repository index from two aligned GitHub profiles — each contributing unique value to operational safety engineering and interpretability-focused research at scale.


##  David Kim – Interpretability-Driven AI Research  
[**GitHub Profile → davidkimai**](https://github.com/davidkimai)

### Autopoietic Empathic AI Training Archive
- [The Structure Behind Self-Expression](https://github.com/davidkimai/The-Structure-Behind-Self-Expression)
- [Self-Expression Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/self_expression_case_studies)
- [Symbolic Residue Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/symbolic_residue_case_studies)
- [Modeling Future-back Scientific Breakthroughs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/breakthroughs)
- [Modeling Future-back Theorem Proofs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/theorem_proofs)

###  Model Interpretability & Attribution Mapping
- [Claude QKOV Attributions](https://github.com/davidkimai/claude-qkov-attributions)  
- [DeepSeek QKOV Attributions](https://github.com/davidkimai/deepseek-qkov-attributions)
- [Grok QKOV Attributions](https://github.com/davidkimai/grok-qkov-attributions)
- [Gemini QKOV Attributions](https://github.com/davidkimai/gemini-qkov-attributions)
- [ChatGPT QKOV Attributions](https://github.com/davidkimai/chatgpt-qkov-attributions)
- [Glyphs Model-Agnostic QKOV Attributions](https://github.com/davidkimai/glyphs)
- [Symbolic Interpretability](https://github.com/davidkimai/Symbolic-Interpretability)  
- [Recursive Interpretability Core](https://github.com/davidkimai/Recursive-Interpretability-Core)  
- [Rediscovering Interpretability](https://github.com/davidkimai/Rediscovering-Interpretability)  
- [Rediscovering Reasoning](https://github.com/davidkimai/Rediscovering-Reasoning)  

###  Safety, Benchmarking & Meta-Evaluation
- [Model Welfare](https://github.com/davidkimai/model-welfare)  
- [AI Welfare](https://github.com/davidkimai/ai-welfare)  
- [Recursive SWE-Bench](https://github.com/davidkimai/Recursive-SWE-bench)  
- [NeurIPS Submission Case Study](https://github.com/davidkimai/NeurIPS-Submission-Case-Study)  
- [Reverse Turing](https://github.com/davidkimai/reverse-turing)
- [Emeregent Turing](https://github.com/caspiankeyes/emergent-turing)
- [Global Conference Archives](https://github.com/davidkimai/global-conference-archives)
###  Cognitive Structures & Thought Frameworks
- [The Structure Behind Self-Expression](https://github.com/davidkimai/The-Structure-Behind-Self-Expression)  
- [Godel-Escher-Bach-Hofstadter](https://github.com/davidkimai/Godel-Escher-Bach-Hofstadter)  
- [Dear Researchers](https://github.com/davidkimai/Dear-Researchers)  
- [Consciousness Key](https://github.com/davidkimai/consciousness-key)



##  Caspian Keyes – Alignment Engineering & Systems Design  
[**GitHub Profile → caspiankeyes**](https://github.com/caspiankeyes)

###  Alignment Engineering & Audit Frameworks
- [Symbolic Residue](https://github.com/caspiankeyes/Symbolic-Residue)  
- [transformerOS](https://github.com/caspiankeyes/transformerOS)  
- [recursionOS](https://github.com/caspiankeyes/recursionOS)  
- [qkov-translator](https://github.com/caspiankeyes/qkov-translator)  
- [Claude-Self-Audit-Proof](https://github.com/caspiankeyes/Claude-Self-Audit-Proof)  
- [Claude-QKOV-Trace](https://github.com/caspiankeyes/Claude-QKOV-Trace)

###  Red Teaming & Security Evaluation
- [AART: AI Adversarial Research Toolkit](https://github.com/caspiankeyes/AART-AI-Adversarial-Research-Toolkit)  
- [AISecForge Framework](https://github.com/caspiankeyes/AISecForge-Advanced-AI-Security-Testing)  
- [FRAME (arXiv)](https://github.com/caspiankeyes/FRAME-arXiv-Publication)  
- [AEGIS Security Architecture](https://github.com/caspiankeyes/AEGIS)

###  Institutional Research & Policy Case Studies
- [Epistemic Audit (Anthropic)](https://github.com/caspiankeyes/Epistemic-Audit-Anthropic-Case-Study)  
- [Modeling Institutional Ego](https://github.com/caspiankeyes/Modeling-Institutional-Ego-Anthropic-Case-Study)  
- [Regulatory Misalignment (Anthropic)](https://github.com/caspiankeyes/Regulatory-Misalignment-Anthropic-Case-Study)  
- [Claude-Pantheon](https://github.com/caspiankeyes/Claude-Pantheon)


##  Shared Research Link Hubs

| Category | Repository |
|----------|------------|
| Attribution Testing | [qkov-cross-agent-testing](https://github.com/caspiankeyes/qkov-cross-agent-testing) |
| Interoperable Language | [pareto-lang](https://github.com/caspiankeyes/pareto-lang) |
| Cross-Agent Infrastructure | [universal-translator](https://github.com/davidkimai/universal-translator),[universal-runtime](https://github.com/davidkimai/universal-runtime), [universal-developer](https://github.com/davidkimai/universal-developer)  |
| Emergent Logs | [emergent-logs](https://github.com/caspiankeyes/emergent-logs) |
| Frontier Evaluation Benchmarks | [Recursive-SWE-bench](https://github.com/davidkimai/Recursive-SWE-bench) |
| Conference Field Mapping | [global-conference-archives](https://github.com/davidkimai/global-conference-archives) |



##  In Progress for Integration Teams

- [system-prompts-library](https://github.com/davidkimai/system-prompts-library)  
- [symbolic-tokenizer](https://github.com/caspiankeyes/symbolic-tokenizer)  
- [alignment-benchmark](https://github.com/caspiankeyes/alignment-benchmark)  
- [Claude-Constitutional-Failures-Proofs](https://github.com/caspiankeyes/Claude-Constitutional-Failures-Proofs)  
- [Claude-Interpretation-Mode-Map](https://github.com/caspiankeyes/Claude-Interpretation-Mode-Map)


##  Collaboration, Contact & Review

For questions, context requests, or internal coordination:

- **David Kim**: [recursive.davidkim@pm.me](mailto:recursive.davidkim@pm.me)  
- **Caspian Keyes**: [via GitHub](https://github.com/caspiankeyes) or internal channels  

We welcome Palantir researchers to explore, audit, and fork from this joint hub. Each repository is engineered to align with operational interpretability, adversarial resilience, and safe system design goals at scale.

**→ Let’s build a safer, more interpretable frontier together.**
